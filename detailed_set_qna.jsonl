{"question": "What are the main concerns with interpreting SET survey data?", "answer": "Several concerns exist with SET survey data interpretation: reliability and validity issues, bias in responses, low correlation with student learning, and misleading single-item measures like 'overall teaching effectiveness.' Response rates impact interpretation - low rates make it difficult to generalize results. Bimodal distributions may indicate only students with strong opinions responded. Bias can occur based on course type, discipline, student background, expected grades, and unconscious biases about instructor characteristics (race, gender, ethnicity, etc.). New teaching methods may initially receive lower scores due to student resistance to change."}
{"question": "How can instructors encourage constructive student feedback in SET surveys?", "answer": "Communicate SET importance in your syllabus and explain how responses will improve the course. Provide specific examples of how previous feedback shaped current classes. Specify what type of feedback is most useful for course improvement. Encourage students to comment on aspects most impactful on their learning experience and provide suggestions about course design and assessment. Remind students to be candid, constructive, and provide detailed feedback. Explain that departmental leadership has access to anonymous responses."}
{"question": "What strategies can increase SET survey response rates?", "answer": "Set aside 10-15 minutes in class during the last week for survey completion (preferably at the start of class). Offer micro-incentives like small extra credit or participation points. Provide explicit instructions on how to access surveys. Ensure students have WiFi and device access. Create a culture of care throughout the quarter. Use mid-quarter feedback surveys. Increase student engagement. Acknowledge survey fatigue and express appreciation. Monitor response rates and send reminders. Check response rates throughout the 11-day survey window."}
{"question": "How should instructors interpret SET survey results?", "answer": "Consider response rates and potential bias in small samples. Avoid focusing only on average scores - examine distribution patterns (normal, skewed, bimodal). Look for patterns in qualitative comments. Use AI tools to summarize themes in open-ended responses. Bring quantitative and qualitative data together for triangulation. Identify areas of strength and improvement. Focus on aspects within your control. Consider negative feedback in broader context - don't fixate on isolated negative comments. Remember that new teaching methods may initially receive lower scores."}
{"question": "What is the Individual Instructor Report for SET surveys?", "answer": "The Individual Instructor Report is provided quarterly to instructors and TAs, typically accessible shortly after grades are submitted. The report includes self-reported background information, student views on classroom experiences, and open-ended feedback. Quantitative data includes means, median, mode, and standard deviation with tables and graphs showing data distribution. Qualitative data is listed alphabetically for review. Reports provide a comprehensive picture including distribution patterns and basic visualizations for quick insights."}
{"question": "How can instructors use SET data to improve teaching quality?", "answer": "Focus on actionable changes you can make. Start with small course adjustments as an easy strategy to begin improvement. Document planned changes and monitor their impact over time. Look for improvements in test scores, project quality, student grades, or affective changes in student attitudes. Use SET data alongside other feedback sources like mid-term evaluations or coursework. Consider participating in UCLA's Holistic Evaluation of Teaching (HET) program for more robust feedback. Remember that SET scores are just one way to get feedback on teaching."}
{"question": "What are the limitations of using averages in SET survey analysis?", "answer": "Using averages assumes students perceive categories as equidistant (e.g., that a rating of 8 is twice as good as 4). Averages assume normal distribution, but SET data is often skewed, making mean comparisons problematic. Averages can hide important differences across student groups. More meaningful comparisons come from examining an instructor's teaching over time, ideally comparing the same course. Including distribution or scatter of scores provides meaningful context about the course environment."}
{"question": "How can instructors handle negative SET feedback constructively?", "answer": "Don't fixate on one or two negative comments - examine feedback in broader context. Remember that anonymous responses may be harsher than identified feedback. Consider consistency of negative feedback to determine if comments reflect broader issues or are outliers. Focus on useful and constructive comments that can inform teaching decisions. Give yourself time to process information and take breaks if needed. Ask a trusted colleague to do a first read and share general themes. Consider exchanging SET feedback with a colleague for objective perspective."}
{"question": "What is the SET survey schedule at UCLA?", "answer": "SET surveys are typically administered at the end of each term. During regular quarters, SET surveys are open for 11 days, beginning Tuesday of Week 9 at 8 a.m. and ending at 8 a.m. the Saturday before Finals week. This timing ensures surveys are completed before final grades are submitted to avoid unfairly influencing student responses based on course grades. Instructors can check response rates throughout this timeframe to identify potential issues early."}
{"question": "How can instructors use AI tools to analyze SET survey comments?", "answer": "Copy comments into generative AI programs (ChatGPT, Copilot, etc.) to summarize or identify general themes from student comments. This provides a quick way to look for patterns and themes in qualitative data, allowing more time to focus on overall sentiments rather than individual comments. However, use AI tools in conjunction with your own analyses to ensure you're not missing nuance in the data. UCLA offers Generative AI tools that can assist with this analysis."}
{"question": "What is the Holistic Evaluation of Teaching (HET) program at UCLA?", "answer": "UCLA's Holistic Evaluation of Teaching (HET) program reimagines how instructors receive robust forms of feedback beyond SET surveys. HET emphasizes professional development and efforts to improve teaching using research-based principles and multiple sources of data. The program includes training instructors on how to interpret and customize their SET surveys, as well as structured peer or classroom observations. UCLA has been a leader in this space with HET deployment. Instructors interested in participating can visit the HET website or complete an interest survey."}
{"question": "How do response rates affect SET survey interpretation?", "answer": "Response rates significantly impact SET data interpretation. Low response rates make it difficult to generalize results to an entire class or assume responders represent the entire class. Small sample sizes increase potential for response bias (responders different than non-responders) and sampling bias. Lower response rates make the impact of outliers more pronounced. He and Freeman (2021) advocate for 50-60% response rates, though this may not be feasible for all courses. Every single response can provide useful feedback on course successes and areas for improvement."}
{"question": "What are the benefits and limitations of SET surveys for teaching improvement?", "answer": "SET surveys provide valuable student perspective on teaching effectiveness and course design, helping instructors identify areas for improvement. They serve as one source of evidence for tenure, merit, and promotion reviews. However, limitations include low correlation with student learning, potential bias based on instructor characteristics, and student resistance to new teaching methods. SETs focus on student satisfaction rather than learning outcomes. The surveys are most useful when combined with other assessment methods and interpreted with awareness of their limitations."}
{"question": "How can instructors create a culture of care to improve SET response rates?", "answer": "Show students throughout the quarter that you value and care about them. Create classrooms with mutual respect between students and instructors/TAs where students feel valued. Model behaviors such as using formative evaluations and highlighting changes made from previous feedback analysis. Foster student belonging throughout the term. Students who feel engaged and valued are more likely to respond to SET surveys. This approach improves both response rates and the quality of feedback received."}
{"question": "What statistical considerations are important when analyzing SET data?", "answer": "When examining SET data, avoid comparisons across instructors, departments, and different courses. More meaningful comparisons come from comparing an instructor's teaching over time, ideally for the same course. Avoid using composite scores as evidence suggests evaluations are more reliable when showing trends across multiple courses. Consider distribution patterns (normal, skewed, bimodal) and use appropriate statistical methods. For non-normal distributions, consider non-parametric testing or data transformation. Include distribution information alongside averages for meaningful context."}
{"question": "How can instructors use mid-quarter feedback to improve SET response rates?", "answer": "Checking in with students through midterm surveys has been shown to improve response rates for end-of-term SET surveys. Mid-quarter feedback demonstrates to students that their input is valued and can lead to course improvements. This practice builds trust and shows students that their feedback matters, making them more likely to complete SET surveys. Mid-quarter feedback also provides instructors with timely information to make adjustments during the current term."}
{"question": "What support is available for interpreting SET survey data at UCLA?", "answer": "The UCLA Teaching and Learning Center has staff dedicated to providing support in assessment, course design, and effective teaching practices. For questions about SET surveys or help interpreting SET ratings, contact assessment@teaching.ucla.edu. The Assessment of Student and Instructor Experience (ASIE) Unit in the TLC can help with processing and interpreting SET ratings. There are also discipline-specific teaching centers (CEILS, HumTech) that can assist with leveraging SET data and implementing new teaching strategies."} 