{"question": "What is the purpose of SET surveys for departmental evaluation committees?", "answer": "SET surveys serve as an important source of evidence for instructors to highlight teaching effectiveness and document improvements during tenure, merit, and promotion reviews at UCLA. However, departments should consider SET data as only one component of a holistic evaluation approach that includes peer evaluations, reviews of teaching materials, and instructor self-statements. The goal is to foster a culture of pedagogical improvement and innovation rather than relying solely on student ratings."}
{"question": "What are the main concerns departments should consider when interpreting SET data?", "answer": "Departments should consider reliability and validity issues (SETs focus on student satisfaction with low correlation to learning), bias (response bias, demographic biases, course type influences), methodological considerations (limitations of traditional data collection methods), meaningful comparisons (avoid cross-instructor/department comparisons), and recognizing SETs as only one data source. Low response rates make generalization difficult and can skew results if strongly opinionated students are overrepresented."}
{"question": "How should departments analyze SET survey context before interpretation?", "answer": "Consider course context factors such as course size, response rates, course level (lower/upper division, graduate), course type (lecture, lab, studio), and modality (online, hybrid, on-campus). Avoid comparisons across instructors teaching different courses or using composite departmental averages. More meaningful comparisons come from examining an instructor's teaching over time, ideally within the same course. If no comparison data exists, group courses by similarity in class size, level, type, and modality."}
{"question": "What are the recommended response rate benchmarks for SET surveys?", "answer": "For class sizes of 25 students or higher, aim for at least 50% response rate with at least 14 completed surveys. For courses with fewer than 25 students, aim for more than 50% response rate for a representative sample. Do not share disaggregated reports with fewer than 10 responses to comply with UCLA's FERPA reporting guidelines and protect student anonymity. Higher response rates provide more reliable teaching evaluations."}
{"question": "How should departments analyze quantitative SET data?", "answer": "Avoid focusing solely on average (mean) scores. Consider the most common response (mode), middle response (median), and response distribution. Visually inspect distributions for patterns like skewed or multimodal distributions. Review all quantitative data, not just subsets. Avoid over-emphasizing small differences or skewed patterns. Note that different departments may use different numerical scales (3-point vs 5-point). Single items like 'overall rating' can be influenced by factors unrelated to student learning."}
{"question": "How should departments summarize qualitative SET data?", "answer": "Focus on comments reflecting learning experiences related to teaching and within instructor control (e.g., course assignments vs room assignments). Look for patterns and common themes rather than singular negative comments. Repeated negative comments deserve attention. Copy comments into programs like Excel or Word to sort by common words, phrases, or sentiment. Consider using word clouds or other visualizations for qualitative feedback analysis."}
{"question": "How can departments use multiple data sources for SET evaluation?", "answer": "Explore quantitative and qualitative data holistically to identify actionable improvement areas. Focus on teaching-related feedback where instructors can take concrete action. Consider SETs as only one piece of evidence alongside peer evaluations, teaching material reviews, and instructor self-statements. Avoid penalizing instructors for lower SET scores when trying innovative teaching methods. Encourage instructors to combine new methods with explanation and facilitation strategies that increase engagement."}
{"question": "What support is available for departments analyzing SET data?", "answer": "Deans, Department Chairs, and Evaluation Coordinators can access raw data and departmental reports through the Teaching and Learning Center. Departments can request assistance with raw data file analysis by emailing assessment@teaching.ucla.edu. The TLC provides staff dedicated to supporting assessment, course design, and effective teaching practices for instructors and TAs."}
{"question": "How should departments handle SET data for innovative teaching methods?", "answer": "Studies show that innovative, evidence-based instructional approaches can initially receive lower SET scores due to student resistance to new methods or frustration with trial-and-error experimentation. Departments should avoid penalizing instructors for lower scores when they're implementing innovative teaching. Instead, encourage instructors to combine new methods with explanation and facilitation strategies, which together have been shown to increase student engagement and improve SET scores over time."}
{"question": "What are the best practices for departmental SET data interpretation?", "answer": "Consider course context (size, level, type, modality) before interpretation. Evaluate response rates against benchmarks (50%+ for classes â‰¥25 students, 14+ responses minimum). Analyze quantitative data beyond averages (mode, median, distribution patterns). Summarize qualitative data for patterns and themes. Use multiple data sources holistically. Focus on actionable, teaching-related feedback. Avoid cross-instructor/department comparisons. Support innovative teaching methods despite potential initial lower scores."}
{"question": "How should departments handle SET data for different course types?", "answer": "Recognize that course type (lecture, lab, studio) and modality (online, hybrid, on-campus) can significantly influence SET ratings. Group similar courses for meaningful comparisons rather than comparing across different course types. Consider course level (lower division, upper division, graduate) as a contextual factor. Avoid using composite scores across different course types. Focus on instructor performance within similar course contexts for fair evaluation."}
{"question": "What statistical considerations are important for departmental SET analysis?", "answer": "Avoid over-emphasizing small differences that may be statistically insignificant. Consider response distributions (normal, skewed, multimodal) when interpreting results. Be aware that different departments may use different numerical scales. Recognize that single-item measures like 'overall effectiveness' can be misleading. Use appropriate statistical methods for non-normal distributions. Include distribution information alongside averages for meaningful context."}
{"question": "How can departments support continuous teaching improvement through SET data?", "answer": "Use SET data to identify actionable areas for pedagogical improvement rather than punitive evaluation. Focus on teaching-related feedback where instructors can take concrete action. Encourage instructors to experiment with evidence-based methods despite potential initial lower scores. Provide resources and support for implementing innovative teaching strategies. Foster a culture of growth and development in teaching practice through constructive feedback and professional development opportunities."}
{"question": "What are the ethical considerations for departments using SET data?", "answer": "Protect student anonymity by not sharing disaggregated reports with fewer than 10 responses. Comply with UCLA's FERPA reporting guidelines. Avoid bias based on instructor demographic characteristics. Recognize potential unconscious biases in student responses. Consider the impact of evaluation decisions on instructor careers and teaching innovation. Use SET data responsibly as one component of holistic evaluation rather than sole determinant of teaching quality."}
{"question": "How should departments handle SET data for different class sizes?", "answer": "Recognize that class size significantly impacts SET interpretation. For large classes (25+ students), aim for 50%+ response rate with 14+ completed surveys. For small classes (<25 students), aim for higher than 50% response rate for representative samples. Avoid comparing SET data across dramatically different class sizes. Consider class size as a contextual factor in evaluation. Group similar-sized courses for meaningful comparisons."}
{"question": "What training do evaluation committee members need for SET interpretation?", "answer": "Committee members are seldom trained on survey data interpretation and may assess ratings through their own experience lens. Provide training on best practices for using student feedback from SET surveys. Educate members about reliability and validity concerns, bias issues, and methodological limitations. Train members to consider context, response rates, and multiple data sources. Emphasize the importance of avoiding cross-comparisons and focusing on actionable feedback."}
{"question": "How can departments balance SET data with other evaluation methods?", "answer": "Use SET data as one component of a comprehensive evaluation approach. Combine with peer evaluations, teaching material reviews, and instructor self-statements. Consider classroom observations, teaching portfolios, and student learning outcomes. Avoid over-reliance on any single data source. Create evaluation rubrics that weight multiple evidence types appropriately. Encourage instructors to provide context and explanations for their teaching approaches and SET results."}
{"question": "What are the limitations of using SET data for personnel decisions?", "answer": "SET data has reliability and validity concerns, potential bias issues, and methodological limitations. Low response rates can skew results. Cross-course comparisons are often inappropriate. SETs focus on student satisfaction rather than learning outcomes. Single-item measures can be misleading. Consider these limitations when using SET data for tenure, merit, and promotion decisions. Supplement with other evidence sources for comprehensive evaluation."}
{"question": "How should departments communicate SET evaluation policies to faculty?", "answer": "Clearly communicate how SET data will be used in evaluation processes. Explain the limitations and appropriate interpretation methods. Provide guidance on response rate benchmarks and statistical considerations. Share best practices for encouraging student participation. Offer training on SET data interpretation for faculty and committee members. Establish transparent evaluation criteria that include multiple data sources beyond SET surveys."}
{"question": "What resources are available for departments implementing SET evaluation policies?", "answer": "The UCLA Teaching and Learning Center provides assessment guides, consultation services, and training for departments. Contact assessment@teaching.ucla.edu for assistance with SET data analysis and interpretation. Access departmental reports and raw data through the TLC. Utilize the Assessment Guide for instructors and departmental quick guides. Consider participating in the Holistic Evaluation of Teaching (HET) program for comprehensive evaluation approaches."} 